{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of DBM"
      ],
      "metadata": {
        "id": "XAbEyT_RI80y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfeUJuIOHROr",
        "outputId": "8e486040-be5b-4245-d8a9-5eacd4d7032a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Probabilities (h1_p) after training:\n",
            " tensor([[0.0501, 0.1335, 0.6574,  ..., 0.7331, 0.1754, 0.8456],\n",
            "        [0.4828, 0.1974, 0.2598,  ..., 0.1755, 0.6429, 0.5675],\n",
            "        [0.6723, 0.0237, 0.4145,  ..., 0.0936, 0.6984, 0.2147],\n",
            "        ...,\n",
            "        [0.1698, 0.0627, 0.9257,  ..., 0.6022, 0.3282, 0.1354],\n",
            "        [0.4189, 0.6550, 0.4878,  ..., 0.7339, 0.1326, 0.3714],\n",
            "        [0.3066, 0.2138, 0.7921,  ..., 0.1113, 0.1922, 0.0228]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class DBM(nn.Module):\n",
        "    def __init__(self, vis_dim=784, hid_dims=[512, 256]):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Parameter(torch.randn(vis_dim, hid_dims[0]) * 0.1)\n",
        "        self.W2 = nn.Parameter(torch.randn(hid_dims[0], hid_dims[1]) * 0.1)\n",
        "    def sample(self, prob):\n",
        "        return torch.bernoulli(prob)\n",
        "    def forward(self, v):\n",
        "        h1_p = torch.sigmoid(v @ self.W1)\n",
        "        return h1_p\n",
        "\n",
        "vis_dim, lr, epochs = 784, 0.01, 5\n",
        "dbm = DBM(vis_dim)\n",
        "opt = torch.optim.Adam(dbm.parameters(), lr=lr)\n",
        "for epoch in range(epochs):\n",
        "  data = torch.randint(0, 2, (32, vis_dim)).float()\n",
        "  h1_p = dbm(data)\n",
        "  if epoch == epochs - 1:\n",
        "    print(f\"Hidden Probabilities (h1_p) after training:\\n\", h1_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of DBN"
      ],
      "metadata": {
        "id": "RkjbDiZUJB3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "class DBN(nn.Module):\n",
        "    def __init__(self, layer_sizes):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes) - 1)])\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = torch.sigmoid(layer(x))\n",
        "        return x\n",
        "    def fine_tune(self, X, y, epochs=5, lr=0.01):\n",
        "        self.fc = nn.Linear(self.layers[-1].out_features, len(torch.unique(torch.Tensor(y))))\n",
        "        opt, loss_fn = optim.Adam(self.parameters(), lr=lr), nn.CrossEntropyLoss()\n",
        "        data, targets = torch.Tensor(X), torch.LongTensor(y)\n",
        "        for epoch in range(epochs):\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(self.fc(self(data)), targets)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        print(\"Weights after training (final layer):\")\n",
        "        print(self.fc.weight)\n",
        "layer_sizes, X_train, y_train = [784, 512, 256, 128], torch.randn(100, 784), torch.randint(0, 10, (100,))\n",
        "dbn = DBN(layer_sizes)\n",
        "dbn.fine_tune(X_train, y_train, epochs=5, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSvZUCgaHS3k",
        "outputId": "069e34d0-b76d-4eeb-aed6-860e63b94e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after training (final layer):\n",
            "Parameter containing:\n",
            "tensor([[-0.0256,  0.0192,  0.0434,  ...,  0.0655,  0.0677,  0.0257],\n",
            "        [-0.0652,  0.0549, -0.0662,  ...,  0.0254, -0.1072,  0.0074],\n",
            "        [ 0.0005,  0.0143, -0.0665,  ...,  0.0539, -0.0244,  0.0661],\n",
            "        ...,\n",
            "        [ 0.0754,  0.0222,  0.0813,  ..., -0.0539, -0.0164, -0.0477],\n",
            "        [-0.0282,  0.0503, -0.0869,  ..., -0.0123,  0.0241, -0.0376],\n",
            "        [-0.0260, -0.0272,  0.0006,  ...,  0.0333, -0.0598, -0.0735]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tes7rwX9Ho90"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}